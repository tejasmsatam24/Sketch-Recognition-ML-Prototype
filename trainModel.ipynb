{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In4HrkCZ_Jyy",
        "outputId": "cc6379d5-65df-421a-98ab-8ebb7b231db3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting quickdraw\n",
            "  Downloading quickdraw-1.0.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from quickdraw) (11.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from quickdraw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->quickdraw) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->quickdraw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->quickdraw) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->quickdraw) (2025.6.15)\n",
            "Downloading quickdraw-1.0.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: quickdraw\n",
            "Successfully installed quickdraw-1.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install quickdraw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gM2-RaCf_qy3",
        "outputId": "abcc21a5-1090-4809-c60d-f80c92b2f61c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downloading aircraft carrier from https://storage.googleapis.com/quickdraw_dataset/full/binary/aircraft carrier.bin\n",
            "download complete\n",
            "loading aircraft carrier drawings\n",
            "load complete\n",
            "downloading airplane from https://storage.googleapis.com/quickdraw_dataset/full/binary/airplane.bin\n",
            "download complete\n",
            "loading airplane drawings\n",
            "load complete\n",
            "downloading alarm clock from https://storage.googleapis.com/quickdraw_dataset/full/binary/alarm clock.bin\n",
            "download complete\n",
            "loading alarm clock drawings\n",
            "load complete\n",
            "downloading ambulance from https://storage.googleapis.com/quickdraw_dataset/full/binary/ambulance.bin\n",
            "download complete\n",
            "loading ambulance drawings\n",
            "load complete\n",
            "downloading angel from https://storage.googleapis.com/quickdraw_dataset/full/binary/angel.bin\n",
            "download complete\n",
            "loading angel drawings\n",
            "load complete\n",
            "downloading animal migration from https://storage.googleapis.com/quickdraw_dataset/full/binary/animal migration.bin\n",
            "download complete\n",
            "loading animal migration drawings\n",
            "load complete\n",
            "downloading ant from https://storage.googleapis.com/quickdraw_dataset/full/binary/ant.bin\n",
            "download complete\n",
            "loading ant drawings\n",
            "load complete\n",
            "downloading anvil from https://storage.googleapis.com/quickdraw_dataset/full/binary/anvil.bin\n",
            "download complete\n",
            "loading anvil drawings\n",
            "load complete\n",
            "downloading apple from https://storage.googleapis.com/quickdraw_dataset/full/binary/apple.bin\n",
            "download complete\n",
            "loading apple drawings\n",
            "load complete\n",
            "downloading arm from https://storage.googleapis.com/quickdraw_dataset/full/binary/arm.bin\n",
            "download complete\n",
            "loading arm drawings\n",
            "load complete\n",
            "downloading asparagus from https://storage.googleapis.com/quickdraw_dataset/full/binary/asparagus.bin\n",
            "download complete\n",
            "loading asparagus drawings\n",
            "load complete\n",
            "downloading axe from https://storage.googleapis.com/quickdraw_dataset/full/binary/axe.bin\n",
            "download complete\n",
            "loading axe drawings\n",
            "load complete\n",
            "downloading backpack from https://storage.googleapis.com/quickdraw_dataset/full/binary/backpack.bin\n",
            "download complete\n",
            "loading backpack drawings\n",
            "load complete\n",
            "downloading banana from https://storage.googleapis.com/quickdraw_dataset/full/binary/banana.bin\n",
            "download complete\n",
            "loading banana drawings\n",
            "load complete\n",
            "downloading bandage from https://storage.googleapis.com/quickdraw_dataset/full/binary/bandage.bin\n",
            "download complete\n",
            "loading bandage drawings\n",
            "load complete\n",
            "downloading barn from https://storage.googleapis.com/quickdraw_dataset/full/binary/barn.bin\n",
            "download complete\n",
            "loading barn drawings\n",
            "load complete\n",
            "downloading baseball bat from https://storage.googleapis.com/quickdraw_dataset/full/binary/baseball bat.bin\n",
            "download complete\n",
            "loading baseball bat drawings\n",
            "load complete\n",
            "downloading baseball from https://storage.googleapis.com/quickdraw_dataset/full/binary/baseball.bin\n",
            "download complete\n",
            "loading baseball drawings\n",
            "load complete\n",
            "downloading basket from https://storage.googleapis.com/quickdraw_dataset/full/binary/basket.bin\n",
            "download complete\n",
            "loading basket drawings\n",
            "load complete\n",
            "downloading basketball from https://storage.googleapis.com/quickdraw_dataset/full/binary/basketball.bin\n",
            "download complete\n",
            "loading basketball drawings\n",
            "load complete\n",
            "downloading bat from https://storage.googleapis.com/quickdraw_dataset/full/binary/bat.bin\n",
            "download complete\n",
            "loading bat drawings\n",
            "load complete\n",
            "downloading bathtub from https://storage.googleapis.com/quickdraw_dataset/full/binary/bathtub.bin\n",
            "download complete\n",
            "loading bathtub drawings\n",
            "load complete\n",
            "downloading beach from https://storage.googleapis.com/quickdraw_dataset/full/binary/beach.bin\n",
            "download complete\n",
            "loading beach drawings\n",
            "load complete\n",
            "downloading bear from https://storage.googleapis.com/quickdraw_dataset/full/binary/bear.bin\n",
            "download complete\n",
            "loading bear drawings\n",
            "load complete\n",
            "downloading beard from https://storage.googleapis.com/quickdraw_dataset/full/binary/beard.bin\n",
            "download complete\n",
            "loading beard drawings\n",
            "load complete\n",
            "downloading bed from https://storage.googleapis.com/quickdraw_dataset/full/binary/bed.bin\n",
            "download complete\n",
            "loading bed drawings\n",
            "load complete\n",
            "downloading bee from https://storage.googleapis.com/quickdraw_dataset/full/binary/bee.bin\n",
            "download complete\n",
            "loading bee drawings\n",
            "load complete\n",
            "downloading belt from https://storage.googleapis.com/quickdraw_dataset/full/binary/belt.bin\n",
            "download complete\n",
            "loading belt drawings\n",
            "load complete\n",
            "downloading bench from https://storage.googleapis.com/quickdraw_dataset/full/binary/bench.bin\n",
            "download complete\n",
            "loading bench drawings\n",
            "load complete\n",
            "downloading bicycle from https://storage.googleapis.com/quickdraw_dataset/full/binary/bicycle.bin\n",
            "download complete\n",
            "loading bicycle drawings\n",
            "load complete\n",
            "downloading binoculars from https://storage.googleapis.com/quickdraw_dataset/full/binary/binoculars.bin\n",
            "download complete\n",
            "loading binoculars drawings\n",
            "load complete\n",
            "downloading bird from https://storage.googleapis.com/quickdraw_dataset/full/binary/bird.bin\n",
            "download complete\n",
            "loading bird drawings\n",
            "load complete\n",
            "downloading birthday cake from https://storage.googleapis.com/quickdraw_dataset/full/binary/birthday cake.bin\n",
            "download complete\n",
            "loading birthday cake drawings\n",
            "load complete\n",
            "downloading blackberry from https://storage.googleapis.com/quickdraw_dataset/full/binary/blackberry.bin\n",
            "download complete\n",
            "loading blackberry drawings\n",
            "load complete\n",
            "downloading blueberry from https://storage.googleapis.com/quickdraw_dataset/full/binary/blueberry.bin\n",
            "download complete\n",
            "loading blueberry drawings\n",
            "load complete\n",
            "downloading book from https://storage.googleapis.com/quickdraw_dataset/full/binary/book.bin\n",
            "download complete\n",
            "loading book drawings\n",
            "load complete\n",
            "downloading boomerang from https://storage.googleapis.com/quickdraw_dataset/full/binary/boomerang.bin\n",
            "download complete\n",
            "loading boomerang drawings\n",
            "load complete\n",
            "downloading bottlecap from https://storage.googleapis.com/quickdraw_dataset/full/binary/bottlecap.bin\n",
            "download complete\n",
            "loading bottlecap drawings\n",
            "load complete\n",
            "downloading bowtie from https://storage.googleapis.com/quickdraw_dataset/full/binary/bowtie.bin\n",
            "download complete\n",
            "loading bowtie drawings\n",
            "load complete\n",
            "downloading bracelet from https://storage.googleapis.com/quickdraw_dataset/full/binary/bracelet.bin\n",
            "download complete\n",
            "loading bracelet drawings\n",
            "load complete\n",
            "downloading brain from https://storage.googleapis.com/quickdraw_dataset/full/binary/brain.bin\n",
            "download complete\n",
            "loading brain drawings\n",
            "load complete\n",
            "downloading bread from https://storage.googleapis.com/quickdraw_dataset/full/binary/bread.bin\n",
            "download complete\n",
            "loading bread drawings\n",
            "load complete\n",
            "downloading bridge from https://storage.googleapis.com/quickdraw_dataset/full/binary/bridge.bin\n",
            "download complete\n",
            "loading bridge drawings\n",
            "load complete\n",
            "downloading broccoli from https://storage.googleapis.com/quickdraw_dataset/full/binary/broccoli.bin\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-2352088462.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mQuickDrawData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawing_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mgenerate_class_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_drawings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecognized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3-2352088462.py\u001b[0m in \u001b[0;36mgenerate_class_images\u001b[0;34m(name, max_drawings, recognized)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuickDrawDataGroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_drawings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_drawings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecognized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecognized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/quickdraw/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, recognized, max_drawings, refresh_data, print_messages, cache_dir)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;31m# download the binary file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBINARY_URL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mQUICK_DRAWING_FILES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_drawings_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;31m# load the drawings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/quickdraw/data.py\u001b[0m in \u001b[0;36m_download_drawings_binary\u001b[0;34m(self, url, filename)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    984\u001b[0m                 \u001b[0mdecoded_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush_decoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from quickdraw import QuickDrawData\n",
        "from quickdraw import QuickDrawDataGroup\n",
        "from pathlib import Path\n",
        "\n",
        "image_size = (256, 256)\n",
        "\n",
        "def generate_class_images(name, max_drawings, recognized):\n",
        "    directory = Path(\"dataset/\" + name)\n",
        "\n",
        "    if not directory.exists():\n",
        "        directory.mkdir(parents=True)\n",
        "\n",
        "    images = QuickDrawDataGroup(name, max_drawings=max_drawings, recognized=recognized)\n",
        "    for img in images.drawings:\n",
        "        filename = directory.as_posix() + \"/\" + str(img.key_id) + \".png\"\n",
        "        img.get_image(stroke_width=3).resize(image_size).save(filename)\n",
        "\n",
        "for label in QuickDrawData().drawing_names:\n",
        "    generate_class_images(label, max_drawings=1200, recognized=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "31cJO4TDLQdM",
        "outputId": "4d611cdd-15ca-4a93-fd65-91ba4f1d37e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU memory growth enabled for 1 GPU(s)\n",
            "Mixed precision enabled for A100 GPU\n",
            "Found 414000 files belonging to 345 classes.\n",
            "Using 331200 files for training.\n",
            "Found 414000 files belonging to 345 classes.\n",
            "Using 82800 files for validation.\n",
            "Dataset optimization applied: prefetching enabled (cache disabled to save RAM)\n",
            "Found 345 classes:\n",
            "  0: The Eiffel Tower\n",
            "  1: The Great Wall of China\n",
            "  2: The Mona Lisa\n",
            "  3: aircraft carrier\n",
            "  4: airplane\n",
            "  5: alarm clock\n",
            "  6: ambulance\n",
            "  7: angel\n",
            "  8: animal migration\n",
            "  9: ant\n",
            "  10: anvil\n",
            "  11: apple\n",
            "  12: arm\n",
            "  13: asparagus\n",
            "  14: axe\n",
            "  15: backpack\n",
            "  16: banana\n",
            "  17: bandage\n",
            "  18: barn\n",
            "  19: baseball\n",
            "  20: baseball bat\n",
            "  21: basket\n",
            "  22: basketball\n",
            "  23: bat\n",
            "  24: bathtub\n",
            "  25: beach\n",
            "  26: bear\n",
            "  27: beard\n",
            "  28: bed\n",
            "  29: bee\n",
            "  30: belt\n",
            "  31: bench\n",
            "  32: bicycle\n",
            "  33: binoculars\n",
            "  34: bird\n",
            "  35: birthday cake\n",
            "  36: blackberry\n",
            "  37: blueberry\n",
            "  38: book\n",
            "  39: boomerang\n",
            "  40: bottlecap\n",
            "  41: bowtie\n",
            "  42: bracelet\n",
            "  43: brain\n",
            "  44: bread\n",
            "  45: bridge\n",
            "  46: broccoli\n",
            "  47: broom\n",
            "  48: bucket\n",
            "  49: bulldozer\n",
            "  50: bus\n",
            "  51: bush\n",
            "  52: butterfly\n",
            "  53: cactus\n",
            "  54: cake\n",
            "  55: calculator\n",
            "  56: calendar\n",
            "  57: camel\n",
            "  58: camera\n",
            "  59: camouflage\n",
            "  60: campfire\n",
            "  61: candle\n",
            "  62: cannon\n",
            "  63: canoe\n",
            "  64: car\n",
            "  65: carrot\n",
            "  66: castle\n",
            "  67: cat\n",
            "  68: ceiling fan\n",
            "  69: cell phone\n",
            "  70: cello\n",
            "  71: chair\n",
            "  72: chandelier\n",
            "  73: church\n",
            "  74: circle\n",
            "  75: clarinet\n",
            "  76: clock\n",
            "  77: cloud\n",
            "  78: coffee cup\n",
            "  79: compass\n",
            "  80: computer\n",
            "  81: cookie\n",
            "  82: cooler\n",
            "  83: couch\n",
            "  84: cow\n",
            "  85: crab\n",
            "  86: crayon\n",
            "  87: crocodile\n",
            "  88: crown\n",
            "  89: cruise ship\n",
            "  90: cup\n",
            "  91: diamond\n",
            "  92: dishwasher\n",
            "  93: diving board\n",
            "  94: dog\n",
            "  95: dolphin\n",
            "  96: donut\n",
            "  97: door\n",
            "  98: dragon\n",
            "  99: dresser\n",
            "  100: drill\n",
            "  101: drums\n",
            "  102: duck\n",
            "  103: dumbbell\n",
            "  104: ear\n",
            "  105: elbow\n",
            "  106: elephant\n",
            "  107: envelope\n",
            "  108: eraser\n",
            "  109: eye\n",
            "  110: eyeglasses\n",
            "  111: face\n",
            "  112: fan\n",
            "  113: feather\n",
            "  114: fence\n",
            "  115: finger\n",
            "  116: fire hydrant\n",
            "  117: fireplace\n",
            "  118: firetruck\n",
            "  119: fish\n",
            "  120: flamingo\n",
            "  121: flashlight\n",
            "  122: flip flops\n",
            "  123: floor lamp\n",
            "  124: flower\n",
            "  125: flying saucer\n",
            "  126: foot\n",
            "  127: fork\n",
            "  128: frog\n",
            "  129: frying pan\n",
            "  130: garden\n",
            "  131: garden hose\n",
            "  132: giraffe\n",
            "  133: goatee\n",
            "  134: golf club\n",
            "  135: grapes\n",
            "  136: grass\n",
            "  137: guitar\n",
            "  138: hamburger\n",
            "  139: hammer\n",
            "  140: hand\n",
            "  141: harp\n",
            "  142: hat\n",
            "  143: headphones\n",
            "  144: hedgehog\n",
            "  145: helicopter\n",
            "  146: helmet\n",
            "  147: hexagon\n",
            "  148: hockey puck\n",
            "  149: hockey stick\n",
            "  150: horse\n",
            "  151: hospital\n",
            "  152: hot air balloon\n",
            "  153: hot dog\n",
            "  154: hot tub\n",
            "  155: hourglass\n",
            "  156: house\n",
            "  157: house plant\n",
            "  158: hurricane\n",
            "  159: ice cream\n",
            "  160: jacket\n",
            "  161: jail\n",
            "  162: kangaroo\n",
            "  163: key\n",
            "  164: keyboard\n",
            "  165: knee\n",
            "  166: knife\n",
            "  167: ladder\n",
            "  168: lantern\n",
            "  169: laptop\n",
            "  170: leaf\n",
            "  171: leg\n",
            "  172: light bulb\n",
            "  173: lighter\n",
            "  174: lighthouse\n",
            "  175: lightning\n",
            "  176: line\n",
            "  177: lion\n",
            "  178: lipstick\n",
            "  179: lobster\n",
            "  180: lollipop\n",
            "  181: mailbox\n",
            "  182: map\n",
            "  183: marker\n",
            "  184: matches\n",
            "  185: megaphone\n",
            "  186: mermaid\n",
            "  187: microphone\n",
            "  188: microwave\n",
            "  189: monkey\n",
            "  190: moon\n",
            "  191: mosquito\n",
            "  192: motorbike\n",
            "  193: mountain\n",
            "  194: mouse\n",
            "  195: moustache\n",
            "  196: mouth\n",
            "  197: mug\n",
            "  198: mushroom\n",
            "  199: nail\n",
            "  200: necklace\n",
            "  201: nose\n",
            "  202: ocean\n",
            "  203: octagon\n",
            "  204: octopus\n",
            "  205: onion\n",
            "  206: oven\n",
            "  207: owl\n",
            "  208: paint can\n",
            "  209: paintbrush\n",
            "  210: palm tree\n",
            "  211: panda\n",
            "  212: pants\n",
            "  213: paper clip\n",
            "  214: parachute\n",
            "  215: parrot\n",
            "  216: passport\n",
            "  217: peanut\n",
            "  218: pear\n",
            "  219: peas\n",
            "  220: pencil\n",
            "  221: penguin\n",
            "  222: piano\n",
            "  223: pickup truck\n",
            "  224: picture frame\n",
            "  225: pig\n",
            "  226: pillow\n",
            "  227: pineapple\n",
            "  228: pizza\n",
            "  229: pliers\n",
            "  230: police car\n",
            "  231: pond\n",
            "  232: pool\n",
            "  233: popsicle\n",
            "  234: postcard\n",
            "  235: potato\n",
            "  236: power outlet\n",
            "  237: purse\n",
            "  238: rabbit\n",
            "  239: raccoon\n",
            "  240: radio\n",
            "  241: rain\n",
            "  242: rainbow\n",
            "  243: rake\n",
            "  244: remote control\n",
            "  245: rhinoceros\n",
            "  246: rifle\n",
            "  247: river\n",
            "  248: roller coaster\n",
            "  249: rollerskates\n",
            "  250: sailboat\n",
            "  251: sandwich\n",
            "  252: saw\n",
            "  253: saxophone\n",
            "  254: school bus\n",
            "  255: scissors\n",
            "  256: scorpion\n",
            "  257: screwdriver\n",
            "  258: sea turtle\n",
            "  259: see saw\n",
            "  260: shark\n",
            "  261: sheep\n",
            "  262: shoe\n",
            "  263: shorts\n",
            "  264: shovel\n",
            "  265: sink\n",
            "  266: skateboard\n",
            "  267: skull\n",
            "  268: skyscraper\n",
            "  269: sleeping bag\n",
            "  270: smiley face\n",
            "  271: snail\n",
            "  272: snake\n",
            "  273: snorkel\n",
            "  274: snowflake\n",
            "  275: snowman\n",
            "  276: soccer ball\n",
            "  277: sock\n",
            "  278: speedboat\n",
            "  279: spider\n",
            "  280: spoon\n",
            "  281: spreadsheet\n",
            "  282: square\n",
            "  283: squiggle\n",
            "  284: squirrel\n",
            "  285: stairs\n",
            "  286: star\n",
            "  287: steak\n",
            "  288: stereo\n",
            "  289: stethoscope\n",
            "  290: stitches\n",
            "  291: stop sign\n",
            "  292: stove\n",
            "  293: strawberry\n",
            "  294: streetlight\n",
            "  295: string bean\n",
            "  296: submarine\n",
            "  297: suitcase\n",
            "  298: sun\n",
            "  299: swan\n",
            "  300: sweater\n",
            "  301: swing set\n",
            "  302: sword\n",
            "  303: syringe\n",
            "  304: t-shirt\n",
            "  305: table\n",
            "  306: teapot\n",
            "  307: teddy-bear\n",
            "  308: telephone\n",
            "  309: television\n",
            "  310: tennis racquet\n",
            "  311: tent\n",
            "  312: tiger\n",
            "  313: toaster\n",
            "  314: toe\n",
            "  315: toilet\n",
            "  316: tooth\n",
            "  317: toothbrush\n",
            "  318: toothpaste\n",
            "  319: tornado\n",
            "  320: tractor\n",
            "  321: traffic light\n",
            "  322: train\n",
            "  323: tree\n",
            "  324: triangle\n",
            "  325: trombone\n",
            "  326: truck\n",
            "  327: trumpet\n",
            "  328: umbrella\n",
            "  329: underwear\n",
            "  330: van\n",
            "  331: vase\n",
            "  332: violin\n",
            "  333: washing machine\n",
            "  334: watermelon\n",
            "  335: waterslide\n",
            "  336: whale\n",
            "  337: wheel\n",
            "  338: windmill\n",
            "  339: wine bottle\n",
            "  340: wine glass\n",
            "  341: wristwatch\n",
            "  342: yoga\n",
            "  343: zebra\n",
            "  344: zigzag\n",
            "\n",
            "Class mapping saved for later use:\n",
            "class_to_index: {'The Eiffel Tower': 0, 'The Great Wall of China': 1, 'The Mona Lisa': 2, 'aircraft carrier': 3, 'airplane': 4, 'alarm clock': 5, 'ambulance': 6, 'angel': 7, 'animal migration': 8, 'ant': 9, 'anvil': 10, 'apple': 11, 'arm': 12, 'asparagus': 13, 'axe': 14, 'backpack': 15, 'banana': 16, 'bandage': 17, 'barn': 18, 'baseball': 19, 'baseball bat': 20, 'basket': 21, 'basketball': 22, 'bat': 23, 'bathtub': 24, 'beach': 25, 'bear': 26, 'beard': 27, 'bed': 28, 'bee': 29, 'belt': 30, 'bench': 31, 'bicycle': 32, 'binoculars': 33, 'bird': 34, 'birthday cake': 35, 'blackberry': 36, 'blueberry': 37, 'book': 38, 'boomerang': 39, 'bottlecap': 40, 'bowtie': 41, 'bracelet': 42, 'brain': 43, 'bread': 44, 'bridge': 45, 'broccoli': 46, 'broom': 47, 'bucket': 48, 'bulldozer': 49, 'bus': 50, 'bush': 51, 'butterfly': 52, 'cactus': 53, 'cake': 54, 'calculator': 55, 'calendar': 56, 'camel': 57, 'camera': 58, 'camouflage': 59, 'campfire': 60, 'candle': 61, 'cannon': 62, 'canoe': 63, 'car': 64, 'carrot': 65, 'castle': 66, 'cat': 67, 'ceiling fan': 68, 'cell phone': 69, 'cello': 70, 'chair': 71, 'chandelier': 72, 'church': 73, 'circle': 74, 'clarinet': 75, 'clock': 76, 'cloud': 77, 'coffee cup': 78, 'compass': 79, 'computer': 80, 'cookie': 81, 'cooler': 82, 'couch': 83, 'cow': 84, 'crab': 85, 'crayon': 86, 'crocodile': 87, 'crown': 88, 'cruise ship': 89, 'cup': 90, 'diamond': 91, 'dishwasher': 92, 'diving board': 93, 'dog': 94, 'dolphin': 95, 'donut': 96, 'door': 97, 'dragon': 98, 'dresser': 99, 'drill': 100, 'drums': 101, 'duck': 102, 'dumbbell': 103, 'ear': 104, 'elbow': 105, 'elephant': 106, 'envelope': 107, 'eraser': 108, 'eye': 109, 'eyeglasses': 110, 'face': 111, 'fan': 112, 'feather': 113, 'fence': 114, 'finger': 115, 'fire hydrant': 116, 'fireplace': 117, 'firetruck': 118, 'fish': 119, 'flamingo': 120, 'flashlight': 121, 'flip flops': 122, 'floor lamp': 123, 'flower': 124, 'flying saucer': 125, 'foot': 126, 'fork': 127, 'frog': 128, 'frying pan': 129, 'garden': 130, 'garden hose': 131, 'giraffe': 132, 'goatee': 133, 'golf club': 134, 'grapes': 135, 'grass': 136, 'guitar': 137, 'hamburger': 138, 'hammer': 139, 'hand': 140, 'harp': 141, 'hat': 142, 'headphones': 143, 'hedgehog': 144, 'helicopter': 145, 'helmet': 146, 'hexagon': 147, 'hockey puck': 148, 'hockey stick': 149, 'horse': 150, 'hospital': 151, 'hot air balloon': 152, 'hot dog': 153, 'hot tub': 154, 'hourglass': 155, 'house': 156, 'house plant': 157, 'hurricane': 158, 'ice cream': 159, 'jacket': 160, 'jail': 161, 'kangaroo': 162, 'key': 163, 'keyboard': 164, 'knee': 165, 'knife': 166, 'ladder': 167, 'lantern': 168, 'laptop': 169, 'leaf': 170, 'leg': 171, 'light bulb': 172, 'lighter': 173, 'lighthouse': 174, 'lightning': 175, 'line': 176, 'lion': 177, 'lipstick': 178, 'lobster': 179, 'lollipop': 180, 'mailbox': 181, 'map': 182, 'marker': 183, 'matches': 184, 'megaphone': 185, 'mermaid': 186, 'microphone': 187, 'microwave': 188, 'monkey': 189, 'moon': 190, 'mosquito': 191, 'motorbike': 192, 'mountain': 193, 'mouse': 194, 'moustache': 195, 'mouth': 196, 'mug': 197, 'mushroom': 198, 'nail': 199, 'necklace': 200, 'nose': 201, 'ocean': 202, 'octagon': 203, 'octopus': 204, 'onion': 205, 'oven': 206, 'owl': 207, 'paint can': 208, 'paintbrush': 209, 'palm tree': 210, 'panda': 211, 'pants': 212, 'paper clip': 213, 'parachute': 214, 'parrot': 215, 'passport': 216, 'peanut': 217, 'pear': 218, 'peas': 219, 'pencil': 220, 'penguin': 221, 'piano': 222, 'pickup truck': 223, 'picture frame': 224, 'pig': 225, 'pillow': 226, 'pineapple': 227, 'pizza': 228, 'pliers': 229, 'police car': 230, 'pond': 231, 'pool': 232, 'popsicle': 233, 'postcard': 234, 'potato': 235, 'power outlet': 236, 'purse': 237, 'rabbit': 238, 'raccoon': 239, 'radio': 240, 'rain': 241, 'rainbow': 242, 'rake': 243, 'remote control': 244, 'rhinoceros': 245, 'rifle': 246, 'river': 247, 'roller coaster': 248, 'rollerskates': 249, 'sailboat': 250, 'sandwich': 251, 'saw': 252, 'saxophone': 253, 'school bus': 254, 'scissors': 255, 'scorpion': 256, 'screwdriver': 257, 'sea turtle': 258, 'see saw': 259, 'shark': 260, 'sheep': 261, 'shoe': 262, 'shorts': 263, 'shovel': 264, 'sink': 265, 'skateboard': 266, 'skull': 267, 'skyscraper': 268, 'sleeping bag': 269, 'smiley face': 270, 'snail': 271, 'snake': 272, 'snorkel': 273, 'snowflake': 274, 'snowman': 275, 'soccer ball': 276, 'sock': 277, 'speedboat': 278, 'spider': 279, 'spoon': 280, 'spreadsheet': 281, 'square': 282, 'squiggle': 283, 'squirrel': 284, 'stairs': 285, 'star': 286, 'steak': 287, 'stereo': 288, 'stethoscope': 289, 'stitches': 290, 'stop sign': 291, 'stove': 292, 'strawberry': 293, 'streetlight': 294, 'string bean': 295, 'submarine': 296, 'suitcase': 297, 'sun': 298, 'swan': 299, 'sweater': 300, 'swing set': 301, 'sword': 302, 'syringe': 303, 't-shirt': 304, 'table': 305, 'teapot': 306, 'teddy-bear': 307, 'telephone': 308, 'television': 309, 'tennis racquet': 310, 'tent': 311, 'tiger': 312, 'toaster': 313, 'toe': 314, 'toilet': 315, 'tooth': 316, 'toothbrush': 317, 'toothpaste': 318, 'tornado': 319, 'tractor': 320, 'traffic light': 321, 'train': 322, 'tree': 323, 'triangle': 324, 'trombone': 325, 'truck': 326, 'trumpet': 327, 'umbrella': 328, 'underwear': 329, 'van': 330, 'vase': 331, 'violin': 332, 'washing machine': 333, 'watermelon': 334, 'waterslide': 335, 'whale': 336, 'wheel': 337, 'windmill': 338, 'wine bottle': 339, 'wine glass': 340, 'wristwatch': 341, 'yoga': 342, 'zebra': 343, 'zigzag': 344}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65536</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">33,554,944</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">345</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">88,665</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65536\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m33,554,944\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m345\u001b[0m)            │        \u001b[38;5;34m88,665\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,359,609</span> (131.07 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,359,609\u001b[0m (131.07 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,358,073</span> (131.07 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,358,073\u001b[0m (131.07 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training with:\n",
            "- Image size: (256, 256)\n",
            "- Batch size: 32\n",
            "- Max epochs: 80\n",
            "- Runtime: A100 GPU\n",
            "- Mixed precision: Enabled\n",
            "- Expected time: ~2.5-4 hours total (2min/epoch)\n",
            "- Early stopping patience: 12 epochs\n",
            "- Cache disabled to prevent RAM overflow\n",
            "Epoch 1/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 41ms/step - accuracy: 0.0693 - loss: 5.0083 - val_accuracy: 0.0127 - val_loss: 13.0651 - learning_rate: 1.0000e-04\n",
            "Epoch 2/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.2363 - loss: 3.4931 - val_accuracy: 0.0282 - val_loss: 10.6459 - learning_rate: 1.0000e-04\n",
            "Epoch 3/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.2952 - loss: 3.1315 - val_accuracy: 0.0578 - val_loss: 8.2519 - learning_rate: 1.0000e-04\n",
            "Epoch 4/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.3269 - loss: 2.9402 - val_accuracy: 0.0590 - val_loss: 8.8947 - learning_rate: 1.0000e-04\n",
            "Epoch 5/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.3536 - loss: 2.7773 - val_accuracy: 0.1031 - val_loss: 5.8374 - learning_rate: 1.0000e-04\n",
            "Epoch 6/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.3709 - loss: 2.6764 - val_accuracy: 0.3549 - val_loss: 2.8103 - learning_rate: 1.0000e-04\n",
            "Epoch 7/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.3871 - loss: 2.5857 - val_accuracy: 0.2098 - val_loss: 4.3242 - learning_rate: 1.0000e-04\n",
            "Epoch 8/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.3996 - loss: 2.5140 - val_accuracy: 0.3024 - val_loss: 3.2432 - learning_rate: 1.0000e-04\n",
            "Epoch 9/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.4097 - loss: 2.4442 - val_accuracy: 0.2053 - val_loss: 4.2403 - learning_rate: 1.0000e-04\n",
            "Epoch 10/80\n",
            "\u001b[1m10349/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4223 - loss: 2.3838\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 40ms/step - accuracy: 0.4223 - loss: 2.3838 - val_accuracy: 0.1849 - val_loss: 5.1145 - learning_rate: 1.0000e-04\n",
            "Epoch 11/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 41ms/step - accuracy: 0.4396 - loss: 2.2931 - val_accuracy: 0.3626 - val_loss: 2.8433 - learning_rate: 5.0000e-05\n",
            "Epoch 12/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 40ms/step - accuracy: 0.4485 - loss: 2.2436 - val_accuracy: 0.3645 - val_loss: 2.8646 - learning_rate: 5.0000e-05\n",
            "Epoch 13/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 41ms/step - accuracy: 0.4557 - loss: 2.2025 - val_accuracy: 0.3661 - val_loss: 2.8405 - learning_rate: 5.0000e-05\n",
            "Epoch 14/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 43ms/step - accuracy: 0.4631 - loss: 2.1727 - val_accuracy: 0.3784 - val_loss: 2.7149 - learning_rate: 5.0000e-05\n",
            "Epoch 15/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 43ms/step - accuracy: 0.4694 - loss: 2.1313 - val_accuracy: 0.3800 - val_loss: 2.7379 - learning_rate: 5.0000e-05\n",
            "Epoch 16/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 43ms/step - accuracy: 0.4729 - loss: 2.1095 - val_accuracy: 0.3140 - val_loss: 3.3848 - learning_rate: 5.0000e-05\n",
            "Epoch 17/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 43ms/step - accuracy: 0.4767 - loss: 2.0783 - val_accuracy: 0.3081 - val_loss: 3.3094 - learning_rate: 5.0000e-05\n",
            "Epoch 18/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 41ms/step - accuracy: 0.4801 - loss: 2.0618 - val_accuracy: 0.3712 - val_loss: 2.8945 - learning_rate: 5.0000e-05\n",
            "Epoch 19/80\n",
            "\u001b[1m10349/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4866 - loss: 2.0225\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 40ms/step - accuracy: 0.4866 - loss: 2.0225 - val_accuracy: 0.2584 - val_loss: 3.7784 - learning_rate: 5.0000e-05\n",
            "Epoch 20/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 40ms/step - accuracy: 0.4955 - loss: 1.9805 - val_accuracy: 0.4474 - val_loss: 2.3520 - learning_rate: 2.5000e-05\n",
            "Epoch 21/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.5047 - loss: 1.9436 - val_accuracy: 0.4390 - val_loss: 2.3749 - learning_rate: 2.5000e-05\n",
            "Epoch 22/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.5080 - loss: 1.9211 - val_accuracy: 0.4203 - val_loss: 2.5228 - learning_rate: 2.5000e-05\n",
            "Epoch 23/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.5117 - loss: 1.9016 - val_accuracy: 0.3781 - val_loss: 2.8513 - learning_rate: 2.5000e-05\n",
            "Epoch 24/80\n",
            "\u001b[1m10349/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5157 - loss: 1.8807\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.5157 - loss: 1.8807 - val_accuracy: 0.4324 - val_loss: 2.4601 - learning_rate: 2.5000e-05\n",
            "Epoch 25/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.5187 - loss: 1.8604 - val_accuracy: 0.3800 - val_loss: 2.8721 - learning_rate: 1.2500e-05\n",
            "Epoch 26/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 41ms/step - accuracy: 0.5209 - loss: 1.8471 - val_accuracy: 0.4287 - val_loss: 2.5215 - learning_rate: 1.2500e-05\n",
            "Epoch 27/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 40ms/step - accuracy: 0.5252 - loss: 1.8278 - val_accuracy: 0.3997 - val_loss: 2.7159 - learning_rate: 1.2500e-05\n",
            "Epoch 28/80\n",
            "\u001b[1m10349/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5286 - loss: 1.8098\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.5286 - loss: 1.8098 - val_accuracy: 0.3620 - val_loss: 3.0422 - learning_rate: 1.2500e-05\n",
            "Epoch 29/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 41ms/step - accuracy: 0.5302 - loss: 1.8087 - val_accuracy: 0.5021 - val_loss: 2.0372 - learning_rate: 6.2500e-06\n",
            "Epoch 30/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.5292 - loss: 1.8050 - val_accuracy: 0.4620 - val_loss: 2.2822 - learning_rate: 6.2500e-06\n",
            "Epoch 31/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.5348 - loss: 1.7881 - val_accuracy: 0.4830 - val_loss: 2.1558 - learning_rate: 6.2500e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.5351 - loss: 1.7787 - val_accuracy: 0.4709 - val_loss: 2.2330 - learning_rate: 6.2500e-06\n",
            "Epoch 33/80\n",
            "\u001b[1m10349/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5377 - loss: 1.7746\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5377 - loss: 1.7746 - val_accuracy: 0.4057 - val_loss: 2.6877 - learning_rate: 6.2500e-06\n",
            "Epoch 34/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.5331 - loss: 1.7849 - val_accuracy: 0.5375 - val_loss: 1.8634 - learning_rate: 3.1250e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.5372 - loss: 1.7762 - val_accuracy: 0.5339 - val_loss: 1.8824 - learning_rate: 3.1250e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.5357 - loss: 1.7759 - val_accuracy: 0.5268 - val_loss: 1.9130 - learning_rate: 3.1250e-06\n",
            "Epoch 37/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5374 - loss: 1.7688 - val_accuracy: 0.5277 - val_loss: 1.9135 - learning_rate: 3.1250e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.5376 - loss: 1.7664 - val_accuracy: 0.5389 - val_loss: 1.8589 - learning_rate: 3.1250e-06\n",
            "Epoch 39/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 40ms/step - accuracy: 0.5416 - loss: 1.7528 - val_accuracy: 0.5292 - val_loss: 1.9030 - learning_rate: 3.1250e-06\n",
            "Epoch 40/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5404 - loss: 1.7540 - val_accuracy: 0.5388 - val_loss: 1.8599 - learning_rate: 3.1250e-06\n",
            "Epoch 41/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5400 - loss: 1.7531 - val_accuracy: 0.5202 - val_loss: 1.9546 - learning_rate: 3.1250e-06\n",
            "Epoch 42/80\n",
            "\u001b[1m10349/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5413 - loss: 1.7499\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5413 - loss: 1.7499 - val_accuracy: 0.5297 - val_loss: 1.9133 - learning_rate: 3.1250e-06\n",
            "Epoch 43/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5396 - loss: 1.7585 - val_accuracy: 0.5448 - val_loss: 1.8292 - learning_rate: 1.5625e-06\n",
            "Epoch 44/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5393 - loss: 1.7578 - val_accuracy: 0.5444 - val_loss: 1.8294 - learning_rate: 1.5625e-06\n",
            "Epoch 45/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5403 - loss: 1.7555 - val_accuracy: 0.5493 - val_loss: 1.8110 - learning_rate: 1.5625e-06\n",
            "Epoch 46/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5415 - loss: 1.7485 - val_accuracy: 0.5472 - val_loss: 1.8202 - learning_rate: 1.5625e-06\n",
            "Epoch 47/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5413 - loss: 1.7479 - val_accuracy: 0.5489 - val_loss: 1.8103 - learning_rate: 1.5625e-06\n",
            "Epoch 48/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5432 - loss: 1.7401 - val_accuracy: 0.5473 - val_loss: 1.8172 - learning_rate: 1.5625e-06\n",
            "Epoch 49/80\n",
            "\u001b[1m10349/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5436 - loss: 1.7377\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5436 - loss: 1.7377 - val_accuracy: 0.5425 - val_loss: 1.8436 - learning_rate: 1.5625e-06\n",
            "Epoch 50/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5416 - loss: 1.7487 - val_accuracy: 0.5503 - val_loss: 1.8026 - learning_rate: 7.8125e-07\n",
            "Epoch 51/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5410 - loss: 1.7463 - val_accuracy: 0.5507 - val_loss: 1.8018 - learning_rate: 7.8125e-07\n",
            "Epoch 52/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5441 - loss: 1.7444 - val_accuracy: 0.5512 - val_loss: 1.8003 - learning_rate: 7.8125e-07\n",
            "Epoch 53/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5423 - loss: 1.7460 - val_accuracy: 0.5493 - val_loss: 1.8101 - learning_rate: 7.8125e-07\n",
            "Epoch 54/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5420 - loss: 1.7448 - val_accuracy: 0.5495 - val_loss: 1.8083 - learning_rate: 7.8125e-07\n",
            "Epoch 55/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5420 - loss: 1.7394 - val_accuracy: 0.5486 - val_loss: 1.8137 - learning_rate: 7.8125e-07\n",
            "Epoch 56/80\n",
            "\u001b[1m10349/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5418 - loss: 1.7399\n",
            "Epoch 56: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5418 - loss: 1.7399 - val_accuracy: 0.5494 - val_loss: 1.8084 - learning_rate: 7.8125e-07\n",
            "Epoch 57/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5416 - loss: 1.7433 - val_accuracy: 0.5519 - val_loss: 1.7974 - learning_rate: 3.9062e-07\n",
            "Epoch 58/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5412 - loss: 1.7440 - val_accuracy: 0.5523 - val_loss: 1.7954 - learning_rate: 3.9062e-07\n",
            "Epoch 59/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5427 - loss: 1.7387 - val_accuracy: 0.5522 - val_loss: 1.7962 - learning_rate: 3.9062e-07\n",
            "Epoch 60/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5427 - loss: 1.7438 - val_accuracy: 0.5518 - val_loss: 1.7969 - learning_rate: 3.9062e-07\n",
            "Epoch 61/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5435 - loss: 1.7388 - val_accuracy: 0.5508 - val_loss: 1.7996 - learning_rate: 3.9062e-07\n",
            "Epoch 62/80\n",
            "\u001b[1m10349/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5424 - loss: 1.7404\n",
            "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5424 - loss: 1.7404 - val_accuracy: 0.5521 - val_loss: 1.7956 - learning_rate: 3.9062e-07\n",
            "Epoch 63/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 40ms/step - accuracy: 0.5431 - loss: 1.7371 - val_accuracy: 0.5527 - val_loss: 1.7930 - learning_rate: 1.9531e-07\n",
            "Epoch 64/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5429 - loss: 1.7421 - val_accuracy: 0.5521 - val_loss: 1.7940 - learning_rate: 1.9531e-07\n",
            "Epoch 65/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5425 - loss: 1.7409 - val_accuracy: 0.5528 - val_loss: 1.7933 - learning_rate: 1.9531e-07\n",
            "Epoch 66/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5443 - loss: 1.7346 - val_accuracy: 0.5529 - val_loss: 1.7926 - learning_rate: 1.9531e-07\n",
            "Epoch 67/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5453 - loss: 1.7332 - val_accuracy: 0.5524 - val_loss: 1.7932 - learning_rate: 1.9531e-07\n",
            "Epoch 68/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5457 - loss: 1.7325 - val_accuracy: 0.5526 - val_loss: 1.7928 - learning_rate: 1.9531e-07\n",
            "Epoch 69/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 40ms/step - accuracy: 0.5434 - loss: 1.7363 - val_accuracy: 0.5526 - val_loss: 1.7935 - learning_rate: 1.9531e-07\n",
            "Epoch 70/80\n",
            "\u001b[1m10349/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5437 - loss: 1.7386\n",
            "Epoch 70: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 40ms/step - accuracy: 0.5437 - loss: 1.7386 - val_accuracy: 0.5524 - val_loss: 1.7933 - learning_rate: 1.9531e-07\n",
            "Epoch 71/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5427 - loss: 1.7359 - val_accuracy: 0.5533 - val_loss: 1.7917 - learning_rate: 1.0000e-07\n",
            "Epoch 72/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 40ms/step - accuracy: 0.5433 - loss: 1.7363 - val_accuracy: 0.5529 - val_loss: 1.7918 - learning_rate: 1.0000e-07\n",
            "Epoch 73/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 40ms/step - accuracy: 0.5437 - loss: 1.7357 - val_accuracy: 0.5532 - val_loss: 1.7918 - learning_rate: 1.0000e-07\n",
            "Epoch 74/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 40ms/step - accuracy: 0.5440 - loss: 1.7352 - val_accuracy: 0.5533 - val_loss: 1.7919 - learning_rate: 1.0000e-07\n",
            "Epoch 75/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 40ms/step - accuracy: 0.5436 - loss: 1.7389 - val_accuracy: 0.5533 - val_loss: 1.7924 - learning_rate: 1.0000e-07\n",
            "Epoch 76/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 40ms/step - accuracy: 0.5458 - loss: 1.7311 - val_accuracy: 0.5527 - val_loss: 1.7927 - learning_rate: 1.0000e-07\n",
            "Epoch 77/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 40ms/step - accuracy: 0.5441 - loss: 1.7333 - val_accuracy: 0.5525 - val_loss: 1.7922 - learning_rate: 1.0000e-07\n",
            "Epoch 78/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 40ms/step - accuracy: 0.5454 - loss: 1.7373 - val_accuracy: 0.5528 - val_loss: 1.7931 - learning_rate: 1.0000e-07\n",
            "Epoch 79/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 40ms/step - accuracy: 0.5444 - loss: 1.7350 - val_accuracy: 0.5528 - val_loss: 1.7924 - learning_rate: 1.0000e-07\n",
            "Epoch 80/80\n",
            "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 40ms/step - accuracy: 0.5451 - loss: 1.7353 - val_accuracy: 0.5532 - val_loss: 1.7919 - learning_rate: 1.0000e-07\n",
            "Restoring model weights from the end of the best epoch: 71.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model saved to: ./models/model_20250707-231404.h5\n",
            "Class labels saved to: ./models/class_labels_20250707-231405.json\n",
            "\n",
            "To use the saved model later:\n",
            "# Load the model\n",
            "model = tf.keras.models.load_model('./models/model_20250707-231404.h5')\n",
            "# Load the class labels\n",
            "with open('./models/class_labels_20250707-231405.json', 'r') as f:\n",
            "    label_data = json.load(f)\n",
            "class_names = label_data['class_names']\n",
            "# Then use predict_with_labels() function for predictions\n"
          ]
        }
      ],
      "source": [
        "import datetime, os\n",
        "import tensorflow as tf\n",
        "from tensorflow import summary\n",
        "\n",
        "from pathlib import Path\n",
        "from matplotlib import pyplot as plt\n",
        "from quickdraw import QuickDrawDataGroup, QuickDrawData\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import sparse_categorical_accuracy\n",
        "from tensorflow.keras.layers import Rescaling\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(f\"GPU memory growth enabled for {len(gpus)} GPU(s)\")\n",
        "\n",
        "        policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
        "        tf.keras.mixed_precision.set_global_policy(policy)\n",
        "        print(\"Mixed precision enabled for A100 GPU\")\n",
        "\n",
        "    except RuntimeError as e:\n",
        "        print(f\"GPU configuration error: {e}\")\n",
        "else:\n",
        "    print(\"No GPUs found, using CPU\")\n",
        "\n",
        "image_size = (256, 256)\n",
        "batch_size = 32  \n",
        "epochs = 80\n",
        "\n",
        "train_ds = image_dataset_from_directory(\n",
        "    \"dataset\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    color_mode=\"grayscale\",\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_ds = image_dataset_from_directory(\n",
        "    \"dataset\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    color_mode=\"grayscale\",\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "n_classes = len(class_names)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)  \n",
        "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "print(\"Dataset optimization applied: prefetching enabled (cache disabled to save RAM)\")\n",
        "\n",
        "print(f\"Found {n_classes} classes:\")\n",
        "for i, class_name in enumerate(class_names):\n",
        "    print(f\"  {i}: {class_name}\")\n",
        "\n",
        "class_to_index = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "index_to_class = {i: class_name for i, class_name in enumerate(class_names)}\n",
        "\n",
        "print(f\"\\nClass mapping saved for later use:\")\n",
        "print(f\"class_to_index: {class_to_index}\")\n",
        "\n",
        "input_shape = (256, 256, 1)\n",
        "\n",
        "model = Sequential([\n",
        "    Rescaling(1. / 255, input_shape=input_shape),\n",
        "\n",
        "    Conv2D(32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    Conv2D(32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    Conv2D(64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    Conv2D(128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    Dense(512, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Dense(256, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Dense(n_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss=SparseCategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = TensorBoard(logdir, histogram_freq=0)\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=12,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.5,  \n",
        "    patience=4,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "callbacks = [tensorboard_callback, early_stopping, reduce_lr]\n",
        "\n",
        "print(f\"\\nStarting training with:\")\n",
        "print(f\"- Image size: {image_size}\")\n",
        "print(f\"- Batch size: {batch_size}\")\n",
        "print(f\"- Max epochs: {epochs}\")\n",
        "print(f\"- Runtime: A100 GPU\")\n",
        "print(f\"- Mixed precision: Enabled\")\n",
        "print(f\"- Expected time: ~2.5-4 hours total (2min/epoch)\")\n",
        "print(f\"- Early stopping patience: 12 epochs\")\n",
        "print(f\"- Cache disabled to prevent RAM overflow\")\n",
        "\n",
        "model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "model_filename = './models/model_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '.h5'\n",
        "model.save(model_filename)\n",
        "\n",
        "import json\n",
        "labels_filename = './models/class_labels_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '.json'\n",
        "with open(labels_filename, 'w') as f:\n",
        "    json.dump({\n",
        "        'class_names': class_names,\n",
        "        'class_to_index': class_to_index,\n",
        "        'index_to_class': index_to_class,\n",
        "        'n_classes': n_classes\n",
        "    }, f, indent=2)\n",
        "\n",
        "print(f\"\\nModel saved to: {model_filename}\")\n",
        "print(f\"Class labels saved to: {labels_filename}\")\n",
        "\n",
        "def predict_with_labels(model, image, class_names):\n",
        "    \"\"\"\n",
        "    Make a prediction and return both the class index and class name\n",
        "    \"\"\"\n",
        "    predictions = model.predict(image)\n",
        "    predicted_index = tf.argmax(predictions[0]).numpy()\n",
        "    predicted_class = class_names[predicted_index]\n",
        "    confidence = predictions[0][predicted_index]\n",
        "\n",
        "    return predicted_index, predicted_class, confidence\n",
        "\n",
        "print(f\"\\nTo use the saved model later:\")\n",
        "print(f\"# Load the model\")\n",
        "print(f\"model = tf.keras.models.load_model('{model_filename}')\")\n",
        "print(f\"# Load the class labels\")\n",
        "print(f\"with open('{labels_filename}', 'r') as f:\")\n",
        "print(f\"    label_data = json.load(f)\")\n",
        "print(f\"class_names = label_data['class_names']\")\n",
        "print(f\"# Then use predict_with_labels() function for predictions\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
